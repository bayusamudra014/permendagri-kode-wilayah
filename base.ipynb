{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permendagri 300.2.2-2138/2025 data structured data extraction\n",
    "\n",
    "Permendagri 300.2.2-2138/2025 is a ministerial decree that is the latest edition of Indonesia's administrative region codes.\n",
    "\n",
    "The raw dataset is a single ~58MB PDF which consists of:\n",
    "* The ministerial decree itself\n",
    "* An appendix which contains the region codes (this is where the data will be extracted from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path\n",
    "input_path = './raw.pdf'\n",
    "output_path = './dist/base.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding relevant tables from the appendix\n",
    "\n",
    "The appendix is split into provinces. For each province has pages for:\n",
    "1. Kabupaten-level summary\n",
    "2. Details up to each desa, including deprecations\n",
    "3. Kecamatan-level summary\n",
    "\n",
    "We are only interested in (2). We need to find the ranges of pages which contain these relevant tables.\n",
    "\n",
    "To do this, we will use `pdftotext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "\n",
    "def find_relevant_pages(path_to_pdf):\n",
    "    with open(path_to_pdf, 'rb') as f:\n",
    "        pdf = pdftotext.PDF(f)\n",
    "\n",
    "        i = 1\n",
    "        ranges = []\n",
    "        is_started = False\n",
    "\n",
    "        for page in pdf:\n",
    "            if 'NAMA PROVINSI /' in page and 'JUMLAH' in page:\n",
    "                ranges.append(i)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ranges = find_relevant_pages(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tables into DataFrames\n",
    "\n",
    "We use `tabula` to extract tables from all relevant pages into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "\n",
    "RANGE=[80, 0, 600, 601]\n",
    "\n",
    "def extract_tables(input_path, pages):\n",
    "    pages = list(pages)\n",
    "\n",
    "    tabula_args = {\n",
    "        'silent': True,\n",
    "        'lattice': True,\n",
    "        'pandas_options': {\n",
    "            'header': None,\n",
    "            'dtype': 'string' # empty cells will be pandas.NA\n",
    "        },\n",
    "    }\n",
    "\n",
    "    result = read_pdf(input_path,\n",
    "                           area=RANGE,\n",
    "                           pages=pages,\n",
    "                           **tabula_args)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pages = relevant_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = extract_tables(input_path, relevant_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing each DataFrame\n",
    "\n",
    "From each DataFrame, we can scrape the Code and a Raw Name. This Raw Name will be sanitised later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import isna\n",
    "import re\n",
    "\n",
    "def is_code(txt):\n",
    "    return re.match('^[0-9]{2}(\\\\.[0-9]{2}(\\\\.[0-9]{2}(\\\\.[1-3][0-9]{3})?)?)?$', str(txt))\n",
    "\n",
    "def parse_frame(frame):    \n",
    "    output = []\n",
    "\n",
    "    # parse each row in the dataframe as a list    \n",
    "    for row in frame.values:\n",
    "        cells = [cell for cell in list(row) if not isna(cell)]\n",
    "        \n",
    "        if len(cells) >= 2 and is_code(cells[0]) and type(cells[1]) == str:\n",
    "            code = cells[0]\n",
    "            raw_name = cells[1]\n",
    "            output.append((code, raw_name))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse all of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_raw_name = []\n",
    "\n",
    "for frame in frames:\n",
    "    tuples = parse_frame(frame)\n",
    "    code_to_raw_name.extend(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we come up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92075\n"
     ]
    }
   ],
   "source": [
    "print(len(code_to_raw_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitising names\n",
    "\n",
    "Two things to sanitise:\n",
    "\n",
    "1. An ordinal number prefixing the name â€“ but some regions have actual numbers in the beginning of their names!\n",
    "2. Carriage returns (`\\r`) in the middle of a names\n",
    "3. Unnecessary in-padded strings such as `P A P U A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_kec = 0\n",
    "counter_kel = 0\n",
    "counter_des = 0\n",
    "\n",
    "def parse_code(code):\n",
    "    global counter_kec, counter_kel, counter_des\n",
    "    if len(code) == 2: # provinsi\n",
    "        counter_kec = 0\n",
    "        counter_kel = 0\n",
    "        counter_des = 0\n",
    "        return '', 'provinsi'\n",
    "    elif len(code) == 5: # kab/kota\n",
    "        counter_kec = 0\n",
    "        counter_kel = 0\n",
    "        counter_des = 0\n",
    "        return '', 'kabkota'\n",
    "    elif len(code) == 8: # kecamatan\n",
    "        counter_kec += 1\n",
    "        counter_kel = 0\n",
    "        counter_des = 0\n",
    "        return str(counter_kec), 'kecamatan'\n",
    "    elif len(code) == 13:\n",
    "        if code[9] == '1': # kelurahan\n",
    "            counter_kel += 1\n",
    "            return str(counter_kel), 'kelurahan'\n",
    "        elif code[9] == '2' or code[9] == '3':\n",
    "            counter_des += 1\n",
    "            return str(counter_des), 'desa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "csv_output = []\n",
    "code_set = set()\n",
    "\n",
    "for row in code_to_raw_name:\n",
    "    code, raw_name = row\n",
    "    code = str(code)\n",
    "    ctr, ctx = parse_code(code)\n",
    "    name = raw_name\n",
    "\n",
    "    if code in code_set:\n",
    "        continue\n",
    "\n",
    "    if ctx == 'provinsi':\n",
    "        name = raw_name.replace('\\\\r', '')\n",
    "    elif ctx == 'kabkota':\n",
    "        name = raw_name.replace('\\\\r', '')\n",
    "        name = re.sub('[0-9]+', '', name)\n",
    "        name = name.strip()\n",
    "    elif re.search('\\\\r' + ctr, raw_name):\n",
    "        name = re.sub('\\\\r(' + ctr + ')?', ' ', name)\n",
    "    else:\n",
    "        name = re.sub('^[0-9]+\\\\s*', '', raw_name)\n",
    "        name = name.replace('\\\\r', ' ')\n",
    "\n",
    "    name = re.sub('\\\\s+', ' ', name)\n",
    "    name = name.strip()\n",
    "\n",
    "    # sanitise cases like `P A P U A`\n",
    "    if re.search('^([A-Za-z] )+[A-Za-z]$', name):\n",
    "        name = re.sub('\\\\s', '', name)\n",
    "    elif name.endswith('elatan.'):\n",
    "        name = name[0:-1]\n",
    "\n",
    "    # sanitise \" which should be '\n",
    "    name = name.replace('\"', \"'\")\n",
    "    csv_output.append((code, name, raw_name))\n",
    "    code_set.add(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in csv_output:\n",
    "        a, b, _ = row\n",
    "        writer.writerow([a, b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the area parameter for running tabula. Values are from Preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 35, 568, 601]\n"
     ]
    }
   ],
   "source": [
    "left = 35\n",
    "top = 90\n",
    "width = 566\n",
    "height = 478\n",
    "\n",
    "y1 = top\n",
    "x1 = left\n",
    "y2 = top + height\n",
    "x2 = left + width\n",
    "\n",
    "coordinates = [y1,x1,y2,x2]\n",
    "\n",
    "print(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate count of each area level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "province = 0\n",
    "city = 0\n",
    "district = 0\n",
    "subdistrict = 0\n",
    "\n",
    "for (code, a, _) in csv_output:\n",
    "    if len(code) == 2:\n",
    "        province += 1\n",
    "    if len(code) == 5:\n",
    "        city += 1\n",
    "    if len(code) == 8:\n",
    "        district += 1\n",
    "    if len(code) == 13:\n",
    "        subdistrict += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 514, 7285, 83762)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(province, city, district, subdistrict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
